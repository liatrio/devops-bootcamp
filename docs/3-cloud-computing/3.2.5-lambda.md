# AWS Lambdas

AWS Lambda is a serverless compute service provided by Amazon Web Services (AWS). It allows developers to run their code without provisioning or managing servers, and only pay for the compute time consumed. Lambdas are event-driven, meaning they are triggered by specific events, such as a user uploading a file to S3 or a change in a DynamoDB table. They can also be used to build and run microservices, perform real-time data processing and analytics, and handle backend tasks such as authentication and authorization. Additionally, Lambdas can be integrated with other AWS services, such as API Gateway, S3, and Kinesis, making it a versatile and powerful tool for building scalable, fault-tolerant applications.

## Exercise - Creating a Lambda function with a trigger

### Overview
- In this exercise we will be using s3 buckets to upload a csv file to a lambda function, and update a DynamoDB table.

### Steps

1. Set up an s3 bucket.

2. Set up a DynamoDb table

3. Write a python program to grab items from a csv and push to a DynamoDB table
    - Make sure to have the right permissions
    - Add a trigger of type s3 bucket
        - Specify an event type
            - Hint: Think of what kind of files you will be uploading to the bucket

    - Make a lambda function that grabs every item from a csv file

    Here is some helpful documentation for [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/dynamodb.html)

``` python

import json
import boto3
import csv

      # lambda function handler here

   record_list = []
   
   try:
      # boto3 resources for s3 here

      # boto3 resource for dynamodb here
       
      table = dynamodb.Table('** DYNAMO-DB-TABLE-NAME ***')
      bucket = event['Records'][0]['s3']['bucket']['name']
      key = event['Records'][0]['s3']['object']['key']
      s3_object = s3_resource.Object(bucket,key)
      
      data = s3_object.get()['Body'].read().decode("utf-8").splitlines()
      lines=csv.reader(data)
      headers=next(lines)
      
      for user_data in lines:
         print(user_data)

         # Create table items here
      
   except Exception as e:
      print(str(e))
            
   return {
      'statusCode': 200,
      'body': json.dumps('CSV success')
   }

```

4. Once your python code is ready, download this csv file [zillow.csv](img3/zillow.csv)

5. Upload the csv file to the bucket you created at the beginning of the exercise.

6. After uploading the file, the lambda function should run. if you're having issues make sure to check the logs (cloud watch), and go over your code.

## Exercise - Creating a Lambda function to spin up ec2 instances

1. Create a Lambda function and verify it was created in the aws console.
2. Next we want to create a DynamoDB database and table.  To do this go to the DynamoDB service page and click `"create table"`.  Create an appropriate name and make the partition key something that will denote different table entries such as "index" or "instance".
3. Create an EC2 instance and tag it with Key: `test-<your_name>-lambda` Value: `True`  or something else that distinguishes your instance from any others.
4. In your Lambda function create:
 - An EC2 client
 - A Dynamodb resource
 - A Table connected to a specific table you have created in that
   Dynamodb resource.

``` python
import json
import boto3
import csv

def lambda_handler(event, context):
   
   try: 
      region = 'us-east-1'
      ec2 = boto3.client('ec2', region_name=region)
      dynamodb = boto3.resource('dynamodb')
      table = dynamodb.Table('<your_table>')
      
     
   except Exception as e:
      print(str(e))
            
   return {
      'statusCode': 200,
      'body': json.dumps('It got to the end of the function')
    }
```

5. Collect and print out the data on the instance we created earlier to see the datas structure as well as some of the available information.

?> One command we can use to grab all of our EC2 instances is describe_instances() with a Filter passed in.

```
filter = [{'Name': 'tag:<your_tag>', 'Values':['<your_value>']}]
instances = ec2 describe_instances(Filters=filter)
```

### Deep Dive

<<<<<<< Updated upstream

Now for something to try on your own.  We want to be able to stop our instance based on the time we last started it. The field for this is "Launch Time".  The command that gives us access to this is describe_instance_status(). Pick a time and test the code to see if our instance is correctly stopped and also store this data along with a few other things you feel we should know about this instance or instances inside our Dynamodb database.

=======
>>>>>>> Stashed changes
1. Create an IAM role with the necessary permissions, including a custom policy to allow your Lambda function to start and stop EC2 instances
2.  We want to be able to stop our instance based on the time we last started it. 
The field for this is "Launch Time".  The command that gives us access to this is `describe_instance_status()`. Pick a time and test the code to see if our instance is correctly stopped.
3. Store this data along with a few other things you feel we should know about this instance or instances inside our Dynamodb database. 

<<<<<<< Updated upstream

=======
>>>>>>> Stashed changes
?> Lambda can do a whole lot more than what we see here, in fact you can do many of the same things you could in the CLI like creating launch configurations, vpc, key pairs, images, etc.  Here is a link to more documentation on this: <https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#client>
