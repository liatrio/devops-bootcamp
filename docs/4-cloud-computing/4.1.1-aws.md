---
docs/4-cloud-computing/4.1.1-aws.md:
  category: Cloud Computing
  estReadingMinutes: 60
---

![Amazon Web Services](img4/aws_light.svg ':size=400px :class=light-mode-img-center')
![Amazon Web Services](img4/aws_dark.svg ':size=400px :class=dark-mode-img-center')

Amazon provides a wide variety of cloud based web services (usually referred to simply as AWS). In section 4.2 we will demonstrate use cases for several different AWS services. The next sections will focus on the basics of interacting with AWS, organizing resources, and managing costs.

?>Check out this video by AWS going over a simple introduction into the world of the [Amazon Simple Storage Service](https://docs.aws.amazon.com/cli/latest/userguide/cli-services-s3.html)

## Accounts and billing

The cost of using AWS services often depends on several different factors. For example, the cost of running an EC2 instance to host Jenkins would depend on the instance tier, amount of CPU time used, and the amount and type of storage. Tier levels generally affect peak performance such as the amount of available CPU processing and memory or type of storage. The general rule is you pay for what you use.

Amazon provides many free tier, trials and low cost solutions which are helpful for experimenting with new solutions (like the exercises in this bootcamp :) but care should be taken to avoid running up unnecessary bills. If you are a Liatrio apprentice talk to your team lead to set up access to our AWS accounts otherwise you can [create an account](https://portal.aws.amazon.com/billing/signup) to complete the upcoming exercises in section 4.2.

### Tips for keeping costs low

- Use low cost resources, such as t2.micro EC2 instances and EBS storage unless you know you need more performance or memory.
- Stop resources such as EC2 instances when not in use. For example if you are using an instance for testing stop it at the end of the day or when you are working on something else.
- Terminate instances and delete associated resources (storage volumes, Elastic IP's, Route53 domain names, etc). Tags (see below) are a good way to group resources together to make them easy to find and clean up.

## Organizing resources

### Tags

> Amazon Web Services (AWS) allows customers to assign metadata to their AWS resources in the form of tags. Each tag is a simple label consisting of a customer-defined key and an optional value that can make it easier to manage, search for, and filter resources. [AWS Tagging Strategies](https://docs.aws.amazon.com/whitepapers/latest/tagging-best-practices/tagging-best-practices.html)

Tags provide a flexible way to manage resources. They can provide information about their intended use, how they were created, who is responsible for them, their expected lifetime or anything else. This is especially important for organizations where resources are created and managed by different people or other tools. In order for them to be effective they should be consistent. Having an organization-wide policy and enforcement for tagging resources can be indispensable.

### Liatrio's Tagging Standards

**Cost Accounting Tags**

- Client: Name of the client
- Project: Specific initiative or project name (Security Swat, Demo Pipeline, etc)

**General Information Tags**

- Environment: Demo, Test, Production
- Application: Descriptive name such as HipChat, Jenkins, etc
- Owner: Humanly readable username i.e. Slack handle
- Automation Candidate: - Yes, No. Used for automation to auto-terminate services and instances that are not meant to be persistent

### Names

Resources names in AWS are actually just tags with the label *Name*. Names should easily identify the owner and purpose of the resource and be concise while differentiating it from other resources. As a general naming convention we recommend something like **OWNER_NAME-TOOL-NAME** which would give you something like **matt-jenkins-master**.

## Console vs CLI

Once your are signed in to AWS you can use the web based [console](https://console.aws.amazon.com/) to create and manage resources. The console is great for monitoring, troubleshooting problems and making quick changes. Amazon also provides an AWS CLI tool which is indispensable for creating repeatable / documentable steps, automating processes and text only environments. The exercises in this chapter will focus on using the command line tool but both provide the same functionality.

### CLI Setup

?>Here is a helpful Liatrio created document detailing how to setup your [aws-vault credentials](https://liatrio.atlassian.net/wiki/spaces/TOOLS/pages/2455076906/aws-vault).

**Requirements**

- Python 2 version 2.6.5+ or Python 3 version 3.3

**Note:** aws-vault is not necessary to use the AWS CLI but adds additional security by storing your credentials in a more secure way.

1. If you do not already have security credentials for your account open [My security credentials](https://console.aws.amazon.com/iam/home?#/security_credentials) in the AWS console; click *Create access key* and download the CSV file or save your credentials someplace safe.
2. Install the [aws-cli](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html) tool: `curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg"` followed by `sudo installer -pkg AWSCLIV2.pkg -target /`
3. Install [aws-vault](https://github.com/99designs/aws-vault): `brew install --cask aws-vault`
4. Add your credentials to aws-vault by running `aws-vault add PROFILE_NAME`. **Note:** replace *PROFILE_NAME* with whatever you would like to call your profile. You will be prompted to enter your AWS credentials and then to create a password to protect them.
5. Test AWS CLI `aws-vault exec PROFILE_NAME -- aws s3 ls`

If this is a new account the output from the last command will be empty but you won't see any errors. The command uses *aws-vault* to execute *aws s3 ls* using the credentials for your profile. *aws s3 ls* lists the s3 buckets your account has access to in your default region.

## Knowledge Check

<div class="quizdown">
  <div id="chapter-4/4.1.1/aws-quiz.js"></div>
</div>

## Deliverables

- Set up AWS CLI and verify you can interact with AWS using it
- Set up aws-vault to track your credentials for you
