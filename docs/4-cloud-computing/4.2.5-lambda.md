---
docs/4-cloud-computing/4.2.5-lambda.md:
  category: Cloud Computing
  estReadingMinutes: 20
  exercises:
    -
      name: Creating a Lambda function with a trigger
      description: Create a Lambda function that sets up an s3 bucket and a DynamoDB, downloads a csv file, and then uses a python script to parse the csv and push all the data into DynamoDB.
      estMinutes: 480
      technologies:
      - AWS
      - AWS Lambda
      - AWS S3
      - AWS DynamoDB
---

# AWS Lambdas

AWS Lambda is a serverless compute service provided by Amazon Web Services (AWS), and an example of a FaaS service. It allows developers to run their code without provisioning or managing servers, and only pay for the compute time consumed. Lambdas are event-driven, meaning they are triggered by specific events, such as a user uploading a file to S3 or a change in a DynamoDB table. They can also be used to build and run microservices, perform real-time data processing and analytics, and handle backend tasks such as authentication and authorization. Additionally, Lambdas can be integrated with other AWS services, such as API Gateway, S3, and Kinesis, making it a versatile and powerful tool for building scalable, fault-tolerant applications.

## Exercise - Lambda function with a trigger

### Overview

- In this exercise we will be using s3 buckets to upload a csv file to a lambda function, and update a DynamoDB table.

### Steps

1. Set up an s3 bucket.
2. Set up a DynamoDb table
3. Download this csv file [zillow.csv](https://people.sc.fsu.edu/~jburkardt/data/csv/zillow.csv)
4. Write a python program to grab items from a csv and push to a DynamoDB table

   - Make sure to have the right permissions
   - Add a trigger of type s3 bucket

     - Specify an event type
       - Hint: Think of what kind of files you will be uploading to the bucket
       - Hint: Grab s3 object, take a look at what the event object is passing in
   - Make a lambda function that grabs every item from a csv file

   Here is some helpful documentation for [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/dynamodb.html)

?> The provided code just includes a way to grab the data from the .csv file you will upload to your S3 bucket. Its broken up into `headers` which are the column names and `data` which is everything else

```python



import json
import boto3
import csv

def lambda_handler(event,context):

   record_list = []

   try:
      # initialize boto3 resource for s3 here

      # initialize boto3 resource for dynamodb here

      # grab your dynamoDB table using your dynamodb resource here

      # grab your s3 object using your s3 resource, you'll need information inside of the "event" object to do so

      data = <your_s3_object>.get()['Body'].read().decode("utf-8").splitlines()
      lines=csv.reader(data)
      headers=next(lines)
      print(headers)

      for user_data in lines:
         print(user_data)

         # Create items here for your dynamodb table based on provided .csv file

   except Exception as e:
      print(str(e))

   return {
      'statusCode': 200,
      'body': json.dumps('CSV success')
   }

```

5. Upload the csv file to the bucket you created at the beginning of the exercise.

6. After uploading the file, the lambda function should run. if you're having issues make sure to check the logs (cloud watch), and go over your code.

7. Lastly alter some values in the csv to verify that the lambda chages the table accordingly.

## Exercise - Lambda function to show information on an EC2 instance

?> Be aware of the API calls that are made when checking EC2 instance data

1. Create a Lambda function and verify it was created in the aws console.

2. Create a DynamoDB database and table.
   - To do this go to the DynamoDB service page and click `"create table"`.
   - Create an appropriate name and make the partition key something that will denote different table entries such as "index" or "instance".

3. Create an EC2 instance
   - Tag it with Key: `test-<your_name>-lambda` Value: `True`  or something else that distinguishes your instance from any others.

4. In your Lambda function create an EC2 client

5. Collect and print out the data on the instance we created earlier to see the data structure as well as some of the available information.

```python
import json
import boto3
import csv

def lambda_handler(event, context):

   try:
      region = '<your_region>'
      # create your EC2 client here for your specified region

      # collect and print data


   except Exception as e:
      print(str(e))

   return {
      'statusCode': 200,
      'body': json.dumps('It got to the end of the function')
    }
```

?> One command we can use to grab all of our EC2 instances from our EC2 client is describe_instances() with a filter passed in.

```bash
filter = [{'Name': 'tag:<your_tag>', 'Values':['<your_value>']}]
instances = ec2.describe_instances(Filters=filter)
```

### Deep Dive - Spinning up and shutting down EC2 instances

1. Create an IAM role with the necessary permissions, including a custom policy to allow your Lambda function to start and stop EC2 instances

2. We want to be able to stop our instance based on the time we last started it.

   The field for this is "Launch Time".  The command that gives us access to this is `describe_instances()`. Pick a time and test the code to see if our instance is correctly stopped.

3. Create a Dynamodb table either through the web interface or just in your lambda function.  However you do it, initialize a resource for it and grab your table.

4. Store this data along with a few other things you feel we should know about this instance or instances inside our Dynamodb database.

?> Lambda can do a whole lot more than what we see here, in fact you can do many of the same things you could in the CLI like creating launch configurations, vpc, key pairs, images, etc.  Here is a link to more documentation on this: [https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#client)

## Deliverables

What is a Lambda and what are they used for?

What is the difference between having a lambda function that runs on each call, rather than having an ec2 instance that is waiting for a call?

Understand how to use multiple AWS resources in conjunction with each other.
