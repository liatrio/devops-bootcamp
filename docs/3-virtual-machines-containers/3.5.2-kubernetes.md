---
docs/3-virtual-machines-containers/3.5.2-kubernetes.md:
  category: Container Orchestration
  estReadingMinutes: 15
  exercises:
    -
      name: Hello Minikube
      description: Complete the 'Hello Minikube' tutorial
      estMinutes: 60
      technologies:
      - Kubernetes
    -
      name: Kind cluster GitHub Actions and Nexus
      description: Create a Kind cluster running your GitHub Actions and Nexus containers
      estMinutes: 600
      technologies:
      - Kubernetes
      - GitHub Actions
      - Nexus OSS
---

# Kubernetes

![k8s image](img3/kubernetes.svg ':size=723x702 :class=icon :alt= k8s image')

There are many different solutions for managing containers but Kubernetes has become one of the most popular and widely used platforms. It is part of a large ecosystem of tools and projects organized by the [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/) which drives development and support for containerized applications. So what is Kubernetes?

> Kubernetes is a portable, extensible open-source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation.
>
> _- [What is Kubernetes?](https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/)_

If you are still having a difficult time understanding what Kubernetes is that is OK. Kubernetes is complicated and we are not going to try to explain all of it in this section. All that you really need to know right now is that you can use it to run Docker containers.

## Architecture

### Cluster

A Kubernetes **cluster** is a set of node machines for running containerized applications. The Kubernetes Master is a collection of three processes that run on a single node in your cluster, which is designated as the master node. Those processes are: kube-apiserver, kube-controller-manager and kube-scheduler.

![cluster image](img3/delivery-k8s-cluster_light.svg ':class=light-mode-img-center :alt= cluster image; light mode')
![cluster image](img3/delivery-k8s-cluster_dark.svg ':class=dark-mode-img-center :alt= cluster image; dark mode')

### Nodes

The **nodes** in a cluster are the machines (VMs, physical servers, etc) that run the applications and workflows. The Kubernetes master controls each node.

![delivery k8s node image](img3/delivery-k8s-node_light.svg ':class=light-mode-img-center :alt= delivery k8s node image; light mode')
![delivery k8s node image](img3/delivery-k8s-node_dark.svg ':class=dark-mode-img-center :alt= delivery k8s node image; dark mode')

### Pods

A **Pod** is the basic execution unit of a Kubernetes application – the smallest and simplest unit in the Kubernetes object model that you create or deploy to run containers.

![delivery k8s pod image](img3/delivery-k8s-pods_light.svg ':class=light-mode-img-center :alt= delivery k8s pod image; light mode')
![delivery k8s pod image](img3/delivery-k8s-pods_dark.svg ':class=dark-mode-img-center :alt= delivery k8s pod image; dark mode')

### Services

A **Service** is an abstraction that defines a logical set of Pods and a policy by which to access them. As pods are created, scaled and destroyed over an application's lifetime the node they are running on and their IP addresses will change. A Service provides a consistent way to communicate with a set of pods regardless of how many pods there are or where they are running.

![delivery k8s service image](img3/delivery-k8s-service_light.svg ':class=light-mode-img-center :alt= delivery k8s service image; light mode')
![delivery k8s service image](img3/delivery-k8s-service_dark.svg ':class=dark-mode-img-center :alt= delivery k8s service image; dark mode')

### Deployments

Deployments abstract away the low-level details of managing Pods. Behind the scenes, **Deployments** rely on **Replica Sets** to manage starting, stopping, scaling, and restarting the Pods if they happen to go down for some reason. Below is an example illustration of a deployment.

![delivery k8s deploy image](img3/delivery-k8s-deploy.gif ':class=img-center :alt= delivery k8s deploy image')

## Labels and Selectors

**Labels** are key/value pairs that are attached to objects, such as pods. Labels are intended to be used to specify identifying attributes of objects that are meaningful and relevant to users, but do not directly imply semantics to the core system. Kubernetes provides built-in support for querying objects via labels and applying bulk operations on the subset selected.

Via a label **Selector**, the client/user can identify a set of objects with the same labels. The label selector is the core grouping primitive in Kubernetes.

A **LIST** operation may specify label selectors to filter the set of objects returned using a query parameter. For example, if we had two separate Pods with the same labels `environment=production,tier=frontend`, we can filter these two Pods by running `kubectl get pods -l environment=production,tier=frontend`. The `-l` is not limited to `get` commands, you can use them with other commands such as `kubectl logs -l tier=frontend` to view logs of all Pods with that label.

For more information, take a read over Kubernetes [Labels and Selectors](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/) page.

## Design

Kubernetes is declarative by design. When you want to change something in the cluster, you simply create/update/delete the resources from etcd via the API server. Various controllers then respond to this change by converging the system to comply with the newly declared state. To best understand, check out this drawing from [Julia Evans](https://jvns.ca/blog/2017/06/04/learning-about-kubernetes/):

![scenes from k8s image](img3/scenes-from-kubernetes-page1.svg ':size=600px :class=img-center :alt= scenes from k8s image')

?>**Declarative:** you declare what you want the system to do - a desired state - and the system will align towards that state. In Kubernetes, you create an API object to represent what you want the system to do. And all the components in the system work to drive towards that state until the object is deleted.

## Exercise 1: Hello Minikube

Minikube is a single node Kubernetes cluster that can be run on a laptop or VM to do local development or just experiment with Kubernetes.

For this exercise follow the instructions in the [Hello Minikube](https://kubernetes.io/docs/tutorials/hello-minikube/#) tutorial to get some experience creating basic resources in Kubernetes. You can use Katacode for the exercise or [install Minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/) locally.

After completing this exercise you should be familiar with the basics of creating Kubernetes resources and using `kubectl` to inspect them. Be sure to spend some time experimenting with `kubectl` commands and exploring the Kubernetes cluster.

## Exercise 2: Deployments and Services with Kubernetes in Docker (Kind)

Kind is a tool for running local Kubernetes clusters using Docker container “nodes”. Using Kind allows us to spin up Kubernetes clusters significantly faster than spawning VMs.

Before we start this exercise, make sure you have [Kind](https://kind.sigs.k8s.io/docs/user/quick-start/#installation) installed. Once Kind is installed, follow along with Kinds [Quick Start](https://kind.sigs.k8s.io/docs/user/quick-start/) documentation to gain some familiarity and experience with Kinds CLI, as well as information on how to create and destroy clusters, and how to interact with those clusters.

In this exercise, you will write YAML files to define Deployment and Service resources to deploy your GitHub Actions Self-Hosted Runner and Nexus containers to the Kind cluster. Note that this is different from how you created resources in the Hello Minikube exercise. Here you will be defining the entire resource spec instead of creating it with a minimal configuration using command line arguments.

Kubernetes resource definitions can be very complicated documents that have a very strict structure. You will need to dig into the Kubernetes documentation and find other examples to be able to create them correctly. You will also need to use commands like `kubectl get`, `kubectl describe` and `kubectl logs` to be able to troubleshoot the resources you create.

After completing this exercise you should be familiar with Kubernetes Deployment, Replica Set, Pod and Service resources, how those resources relate to each other, as well as using `kubectl` to create and inspect the resources.

1. Start by creating a cluster using Kind. Afterwards, to avoid cluttering our cluster, we want to add a namespace to our cluster to group all of our resources. Name the new namespace, `bootcamp`.

2. Create a file called `deployment-gha.yaml` and define a [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) to run your GitHub Actions Self-Hosted Runner container. Be sure that your deployment deploys to the new namespace that was created in the previous step instead of the `default` namespace. Kind does not spin up a local container image registry out-the-box. Find a way to load the images to Kind before running `kubectl apply -f deployment-gha.yaml` and checking that the Deployment was created and that the Pod is running. Make sure to version your images before loading to Kind.

  ?> As long as the container `imagePullPolicy` is set to `IfNotPresent` (default) or `Never`, the Kubernetes cluster will try to find the container image in your local Docker images. You must make sure the image is built and the tag matches what is in the Deployment spec. Read more about how Pods use [container images](https://kubernetes.io/docs/concepts/containers/images/).

3. Go to the GitHub web portal for your spring-petclinic fork and verify that your self hosted runner is showing up correctly.

4. Repeat steps 2 - 3, creating Deployment and Service files for Nexus.

  ?> You can use port forwarding in kubernetes to verify Nexus is accessible.

  ?> For the GitHub Action Self-Hosted runner to talk to Nexus, you will need to set up a `service-nexus.yaml` also: [Service](https://kubernetes.io/docs/concepts/services-networking/service/)

5. Trigger your GitHub Action in the web portal and verify that it still runs correctly and uploads an artifact to Nexus.

## Knowledge Check

<div class="quizdown">
  <div id="chapter-3/3.5.2/k8s-quiz.js"></div>
</div>
