# AWS Lambdas

AWS Lambda is a serverless compute service provided by Amazon Web Services (AWS), and an example of a FaaS service. It allows developers to run their code without provisioning or managing servers, and only pay for the compute time consumed. Lambdas are event-driven, meaning they are triggered by specific events, such as a user uploading a file to S3 or a change in a DynamoDB table. They can also be used to build and run microservices, perform real-time data processing and analytics, and handle backend tasks such as authentication and authorization. Additionally, Lambdas can be integrated with other AWS services, such as API Gateway, S3, and Kinesis, making it a versatile and powerful tool for building scalable, fault-tolerant applications.

## Exercise - Creating a Lambda function with a trigger

### Overview

- In this exercise we will be using s3 buckets to upload a csv file to a lambda function, and update a DynamoDB table.

### Steps

1. Set up an s3 bucket.
2. Set up a DynamoDb table (or you can create one inside the lambda function)
3. Write a python program to grab items from a csv and push to a DynamoDB table

   - Make sure to have the right permissions
   - Add a trigger of type s3 bucket

     - Specify an event type
       - Hint: Think of what kind of files you will be uploading to the bucket
   - Make a lambda function that grabs every item from a csv file

   Here is some helpful documentation for [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/dynamodb.html)

?> The provided code just includes a way to grab the data from the .csv file you will upload to your S3 bucket. Its broken up into `headers` which are the column names and `data` which is everything else

```python

import json
import boto3
import csv

def lambda_handler(event,context):

   record_list = []
   
   try:
      # initialize boto3 resource for s3 here

      # initialize boto3 resource for dynamodb here
     
      # grab your dynamoDB table using your dymanodb resource here
    
      # grab your s3 object using your s3 resource, you'll need information inside of the "event" object to do so
    
      data = <your_s3_object>.get()['Body'].read().decode("utf-8").splitlines()
      lines=csv.reader(data)
      headers=next(lines)
      print(headers)
    
      for user_data in lines:
         print(user_data)

         # Create items here for your dynamodb table based on provided .csv file
    
   except Exception as e:
      print(str(e))
          
   return {
      'statusCode': 200,
      'body': json.dumps('CSV success')
   }

```


4. Once your python code is ready, download this csv file [zillow.csv](https://people.sc.fsu.edu/~jburkardt/data/csv/zillow.csv)
5. Upload the csv file to the bucket you created at the beginning of the exercise.
6. After uploading the file, the lambda function should run. if you're having issues make sure to check the logs (cloud watch), and go over your code.

## Exercise - Creating a Lambda function show information on an EC2 instance

1. Create a Lambda function and verify it was created in the aws console.
2. Next we want to create a DynamoDB database and table.  To do this go to the DynamoDB service page and click `"create table"`.  Create an appropriate name and make the partition key something that will denote different table entries such as "index" or "instance".
3. Create an EC2 instance and tag it with Key: `test-<your_name>-lambda` Value: `True`  or something else that distinguishes your instance from any others.
4. In your Lambda function create an EC2 client
5. Collect and print out the data on the instance we created earlier to see the datas structure as well as some of the available information.

```python
import json
import boto3
import csv

def lambda_handler(event, context):
   
   try: 
      region = '<your_region>'
      # create your EC2 client here for your specified region
    
      # collect and print data
    
   
   except Exception as e:
      print(str(e))
          
   return {
      'statusCode': 200,
      'body': json.dumps('It got to the end of the function')
    }
```

?> One command we can use to grab all of our EC2 instances from our EC2 client is describe_instances() with a filter passed in.

```
filter = [{'Name': 'tag:<your_tag>', 'Values':['<your_value>']}]
instances = ec2.describe_instances(Filters=filter)
```

### Deep Dive - Spinning up and shutting down EC2 instances

1. Create an IAM role with the necessary permissions, including a custom policy to allow your Lambda function to start and stop EC2 instances
2. We want to be able to stop our instance based on the time we last started it.
   The field for this is "Launch Time".  The command that gives us access to this is `describe_instance_status()`. Pick a time and test the code to see if our instance is correctly stopped.
3. Create a Dynamodb table either through the web interface or just in your lambda function.  However you do it, initialize a resource for it and grab your table.
4. Store this data along with a few other things you feel we should know about this instance or instances inside our Dynamodb database.

?> Lambda can do a whole lot more than what we see here, in fact you can do many of the same things you could in the CLI like creating launch configurations, vpc, key pairs, images, etc.  Here is a link to more documentation on this: [https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#client](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#client)
